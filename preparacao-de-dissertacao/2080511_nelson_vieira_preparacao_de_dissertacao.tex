\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\graphicspath{ {./assets/} }
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[hidelinks]{hyperref}
\hypersetup{
    colorlinks=false,
}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Capacitando os utilizadores para os seus direitos de privacidade na Internet of Things\\
}

\author{\IEEEauthorblockN{Nelson Vieira}
\IEEEauthorblockA{\textit{Faculdade de Ciências Exatas e da Engenharia} \\
\textit{Universidade da Madeira}\\
Funchal, Portugal \\
2080511@student.uma.pt}
\and
\IEEEauthorblockN{Mary Barreto (Orientadora)}
\IEEEauthorblockA{\textit{Faculty of Exact Sciences and Engineering} \\
\textit{University of Madeira}\\
Funchal, Portugal \\
mary.barreto@staff.uma.pt}
}

\maketitle

\begin{abstract}
Os dispositivos da Internet of Things (IoT), ou Internet das Coisas, estão
em toda parte, desde o nascimento da computação ubíqua que a vida quotidiana
humana é imaginada contendo milhões de dispositivos que controlam todos os
aspectos de nossas vidas. Hoje em dia temos carros inteligentes, casas inteligentes,
cidades inteligentes, \textit{wearables} entre outras coisas que usam vários
tipos de dispositivos e vários tipos de redes para comunicarem entre si. Estes
dispositivos criam novas formas de recolher e processar dados pessoais de
utilizadores e não utilizadores. A maioria dos utilizadores finais nem sabem
ou têm pouco controlo sobre as informações que estão sendo recolhidas por
esses sistemas. Este trabalho faz uma abordagem holística para este problema,
fazendo primeiro uma revisão da literatura, em seguida, realizando uma pesquisa
para saber mais sobre o conhecimento geral do público e, finalmente, com base
nas informações recolhidas, é proposto um sistema que fornece aos utilizadores
informações sobre os dispositivos que estão próximos e como proteger os dados
que não desejam compartilhar com esses dispositivos, este sistema é capaz de
detectar que tipo de dispositivos estão próximos, que tipo de dados são recolhidos
por esses dispositivos, mostrar opções de privacidade ao utilizador quando
é possível fazê-lo e o que pode ser feito para evitar que dados indesejados
sejam recolhidos.

% Internet of things (IoT) devices are everywhere, since the birth of ubiquitous
% computing that human every day life is envisioned containing millions of
% devices that control every aspect of our lives. Today we have smart cars,
% smart houses, smart cities, wearables among other things that use various
% types of devices and various types of networks to communicate. These devices
% create new ways of collecting and process personal data from users and
% non-users. Most end users are not even aware or have little control over
% the information that is being collected by these systems. This work takes
% an holistic approach to this problem by first doing a literature review,
% then by doing a survey to gather information about the general knowledge
% of Portugal's population in this very topic and then, based on the information
% gathered, it is proposed a system that gives users information about the
% devices that are nearby and how to protect the data that they do not want
% to share with these devices, this system is capable of detecting what type
% of devices are nearby, what kind of data is collected by these devices,
% show privacy choices to the user when it is possible to do so and what can
% be done to protect unwanted data from being collected.
\end{abstract}

\begin{IEEEkeywords}
privacy, Internet of Things, ubiquitous computing, privacy assistant
\end{IEEEkeywords}

\section{Introduction}

Privacy as we know it is a somewhat recent concept \cite{vincent2016privacy, moore2017privacy},
before the digital age there was barely any notion of privacy for most
people. For many centuries most people used to reside in small communities
where they were continuously involved in one another's lives. Even more
recent is the idea that privacy is a crucial component of personal security,
in contrast to the undeniable necessity of public security, including the
requirement for guarded walls and closed doors. Long seen as a luxury, privacy
is still usually regarded as a good to have rather than an essential
requirement, even though it is acknowledged as a human right, as present
in article 12 of the Universal Declaration of Human Rights \cite{RooseveltUniversal}:
``No one shall be subjected to arbitrary interference with his privacy,
family, home or correspondence, nor to attacks upon his honour and reputation.
Everyone has the right to the protection of the law against such interference
or attacks''. Privacy can be defined \cite{InternationalWhat, SpiekermannEngineering}
as the right to govern how personal information and data is collected, stored,
and used, it frequently involves handling sensitive information with care,
and as such, organizations must be open and honest about the kind of data
they plan to gather, why they need it, and where and with whom they plan
to share it. Users should have the right to control their shared information.

This definition can cause some confusion with the idea of security \cite{HIVDifference}
and although privacy and security are interconnected, security involves
measures taken to safeguard data from risk, threat or danger, it frequently
alludes to safety. It is the practice of keeping users' personal information
and data safe and preventing unauthorized access to it. The primary contrast
between privacy and security is that the former deals with personal information
to individuals and how they want their data used and maintained, whilst
the latter deals with its protection from possible threats. Security can
exist without privacy, but the opposite is not true. For managing sensitive
and personal data, privacy and computer security are equally crucial. Users
should be aware of the internal procedures regarding the collection, processing,
retention, and sharing of personal information.

Concerns about digital privacy have been growing \cite{emami2019exploring, park2022personal, zhang2022peer}
in the last few years, especially after the Anonymous decentralized hacker
group cyber attacks, WikiLeaks and Snowden's leaked top secret documents
from United State's National Security Agency. These concerns can be noted
with the increase of written literature on the subject, when searching for
terms like ``privacy'', ``online privacy'', ``digital privacy'' in Google
Scholar, ACM Digital Library or Science Direct it can be seen that, in the
last 5 years, it returns about 5000000, 650000 and 80000 documents respectively,
including articles, books, conference papers etc.

Most research has focused on the web, while privacy in IoT systems has not
been explored as much. Because IoT devices are becoming more prevalent,
new methods of communicating, gathering, and analyzing data emerge.
Because there is already a substantial quantity of research focusing on web
privacy rather than IoT privacy, it is a lot more fertile ground to explore
the issue of privacy in the context of the IoT.

\textit{Internet of Things} is a term that first appeared in the 1990s,
and it may be linked to Mark Weiser's paper on ubiquitous computing \cite{weiser1991computer}
and the growth of devices of all sizes that communicate with one another
to do various tasks, making Weiser's dream a reality. The first use of the
term \textit{Internet of Things} was in 1999 by British technology pioneer
Kevin Ashton \cite{KevinThat}, executive director of the Auto-ID Center at
Massachusetts Institute of Technology (MIT), to describe a system in which
items may be connected to the internet by sensors. He came up with the phrase
while giving a presentation for Procter \& Gamble to highlight the value
of linking Radio-Frequency Identification (RFID) tags used in corporate
supply chains to the internet in order to count and track goods without the
need for human assistance. These devices are used in various applications,
starting at home \cite{marikyan2019systematic} with thermostats, fridges,
microwaves, etc, moving on to smart cars \cite{arena2020overview}, the
educational system \cite{al2020survey}, our clothes and our watches \cite{niknejad2020comprehensive}
and even into outer space \cite{AkyildizInternet}. IoT resources may include
IoT equipment (like smart home assistants and autonomous vehicles), IoT
services (like video analytics services linked to smart cameras and indoor
position tracking systems), or IoT apps (like smart TV remote apps) that
track and use information about us. Internet of Things is now widely used
to describe situations in which a range of objects, gadgets, sensors, and
ordinary items are connected to the internet and have computational capabilities.

The idea of using computers and networks in order to monitor and manage devices
is nothing new, despite the term \textit{Internet of Things} being relatively
recent. By the late 1970s, technologies for remotely monitoring electricity
grid meters through telephone lines were already in use in the corporate
sector. Wireless technology improvements in the 1990s permitted the widespread
adoption of corporate and industrial machine-to-machine (M2M) solutions for
equipment monitoring and operation. Many early M2M solutions, on the other
hand, relied on proprietary purpose-built networks or industry-specific
standards rather than internet standards. To connect devices other than
computers to the internet is not a new concept. A Coke machine at Carnegie
Mellon University's Computer Science Department \cite{EverhartInteresting}
was the first ubiquitous device to be linked to the internet. The system,
which was created in 1982, remotely observed the out of stock lights on the
pressing buttons of the vending machine and broadcast the state of each row
of the vending machine on the network so that it could be accessed using
the Name/Finger protocol through a terminal. In 1990, a toaster that could
be turned on and off over the internet that was created by John Romkey \cite{RomkeyToast},
was demonstrated at the Interop Internet Networking show.

The Internet of Things can be defined as: ``An open and comprehensive network
of intelligent objects that have the capacity to auto-organize, share information,
data and resources, reacting and acting in face of situations and changes
in the environment'' \cite{madakam2015internet}.

IoT is one of the fastest growing technologies \cite{MohammadState}, it is
predicted that it will grow into the trillions of devices by 2030 \cite{SarawiInternet},
and with this expansion new security vulnerabilities and data gathering dangers
appear, the lack of security in these devices makes them ideal targets for
privacy violations and inadequate customer disclosure of device capabilities
and data practices aggravates privacy and security issues.

Privacy in IoT systems in not seen as a crucial factor in development \cite{alhirabi2021security}.
Specific standards for privacy options have been imposed by data privacy
regulations including the General Data Protection Regulation (GDPR) and
California Consumer Privacy Act (CCPA), but even these regulations have been
criticized \cite{peloquin2020disruptive, gladis2022weaponizing, gentile2022deficient, green2022flaws, byun2019privacy}.

\section{Literature Review}

\par
This section provides an overview of the recent literature with the themes
that were found to be more relevant for this work.

\subsection{Privacy Paradox}

The use of a variety of digital devices have numerous advantages, but they
also bring with them the ubiquity of data capturing equipment, therefore,
it is understandable why the majority of online users have serious concerns
about the privacy of their personal data. However, the opinions expressed
are starkly at odds with the reality, according to Thomson et al. \cite{DarrenState}
report on the state of privacy, that just one in four European users read
the terms and conditions in their entirety prior to making an online purchase
or subscribing to a service, 59\% admitted to only quickly scanning the terms
and conditions before completing a purchase, while 14\% admitted to never
reading them at all, 30\% of the respondents would even swap their email
address to win a reward, or entry into a raffle, while 17\% would do so to
get an app and 30\% would do it for money.

This is what is called a privacy paradox, there have been multiple papers
written on this subject \cite{solove2021myth, WilliamsPrivacy, lee2021investigating, goad2021privacy, gerber2018explaining},
some papers attempt a theoretical explanation while others attempt an empirical
one. There has been very different interpretations or explanations of this
paradox, a few papers \cite{wilson2012unpacking, warshaw2015can, lee2015privacy}
apply the theoretical concept of the \textit{homo economicus} \cite{zak2008moral},
which is the representation of people as beings who constantly act in a way
that is logical and self-interested, not worrying about morality or ethics,
and who do so to the best of their ability, to the context of privacy. Different
cognitive biases and heuristics can influence how consumers make decisions,
according to several studies on consumer choice behavior \cite{acquisti2007can, knijnenburg2013dimensionality, wakefield2013influence, flender2012type}.
According to several articles \cite{dienlin2015privacy, baek2014solving},
this paradox might be explained by the fact that some people have genuinely
experienced online privacy assaults and that most privacy views are therefore
based on heuristics or secondhand accounts. Taddicken's study \cite{taddicken2014privacy}
argues that peer pressure is the reason people have this contradictory behavior,
Norberg et al. \cite{norberg2007privacy} explains this paradox by suggesting
that while perceived risk affects reported attitudes and behavioral intentions,
trust has a direct impact on privacy behavior, while others \cite{flender2012type, kokolakis2017privacy}
rely on quantum theory. Brandimarte et al. \cite{brandimarte2013misplaced}
have explored the idea that when it comes to their data privacy, users have
an \textit{illusion of control}.

This paradox has been proven to be vitiated by a number of empirical studies \cite{dienlin2015privacy, xie2019consumers, SCHWAIG20131, sannon2018privacy},
online privacy practices are founded on separate privacy mindsets and so
they are not inherently paradoxical.

\subsection{Differential Privacy}

The notion of differential privacy, according to Michael Kearns \cite{kearns2019ethical},
is based on three important principles. The first being that ``differential
privacy requires that adding or removing the data record of a single individual
not change the probability of any outcome by much''. The second principle
being that ``no outside observer can learn very much about any individual
because of that person's specific data''. The third important principle
being that ``for every individual in the dataset, and for any observer no
matter what their initial beliefs about the world were, after observing
the output of a differentially private computation, their posterior belief
about anything is close to what it would have been had they observed the
output of the same computation run without the individual's data''.

Differential privacy has the potential to significantly increase individual
privacy protection, by purposefully adding noise into a dataset, it gives
plausible deniability to any individual who may have had their data exploited
while still being able to calculate statistics with relatively high precision.
Although algorithms that deal with notions of fairness, ethics, and privacy
are hard to implement because of the subjectivity of these concepts, and
differential privacy algorithms are no different, they can still help in
regards to addressing technology's inherent moral quandaries.

There exist other algorithms that aim to preserve privacy in the same way
as differential privacy such as Google's box blurring algorithm \cite{FromeLarge}
that is used in the Google Map's street view, Microsoft's Visor \cite{poddar2020visor}
which is a video-analytics-as-a-service tool and Shokri and Shmatikov's
\cite{ShokriPrivacy} system for collaborative deep learning, however, in
general, these algorithms struggle with high computational cost, internal
attacks, or non-provable privacy.

Zhao et al. \cite{ZhaoSurvey} conduct a SLR on differential privacy for
unstructured data. The authors present differential privacy methods for sensitive
content in image, audio, video, and text data. They compare the various methods
and perform utility analyses for each method, highlighting the benefits and
drawbacks of each, the utility loss is measured in experimental evaluations
between the actual data and its obfuscated variant. They come to the conclusion
that differential privacy as well as its variations give stringent privacy
protections for unstructured data against attackers with unpredictable background
knowledge. They also suggest potential future study subjects that have yet
to be investigated.

\subsection{State of the Art}

There have been a number of systematic literature reviews (SLR) \cite{Gupta2022Privacy, Kuhtreiber2022survey, sicari2015security, LinSurvey}
and systematic mapping reviews \cite{porras2018security, ahmed2019aspects}
done to study privacy and security issues in IoT.

In Gupta and Ghanavati's \cite{Gupta2022Privacy} SLR, the authors review
papers with methodologies and techniques that identify privacy risks or
notify users about these risks. They divide the literature into the following
categories: `Ontological Modeling and Semantic-based Approaches', `Data-Driven
Approaches', `Source Code Analysis-based Approaches', `User Studies and
Survey-based Approaches', `Blockchain-based Approaches' and `Architectural
and Framework-based Approaches'. They then examine current literature on
these three prerequisites. The findings show that: most works concentrate
on single IoT devices when addressing privacy threats; When analyzing privacy
issues, key privacy factors such as data reduction and data aggregation are
overlooked; existing studies ignored the sensitivity of the obtained information;
most useful studies did not include a diverse range of users when assessing
privacy problems; no work has been done to discover compliance difficulties
between an IoT application and different privacy rules; and current research
does not place a premium on providing consumers with real-time privacy notices.
However, this SLR has the following limitations: the authors only chose articles
and not thesis or books and from the selected papers, only the ones written
in english were considered.

Kühtreiber et al. \cite{Kuhtreiber2022survey} evaluate the frameworks and
tools established for developers, specifically in the case of IoT, and find
that current solutions are difficult to use, only successful in limited
scenarios, and insufficient to handle the privacy problems inherent in IoT
development. This study lacks a comprehensive gap review of the chosen
literature, along with research questions establishing the significance of
the articles chosen.

Sicari et al. \cite{sicari2015security} examine current research and ongoing
activities that focus on IoT privacy and security solutions. The authors
start by describing the requirements for IoT privacy and security, such as
access control, confidentiality, and authentication. The authors then conduct
a literature study in connection to these three needs. The authors came to
the conclusion that IoT privacy issues have only been partially examined and
that further attention is required. The study, however, has flaws: the prior
research analysis focuses primarily on security needs while ignoring privacy
considerations; the authors do not conduct a thorough gap analysis on the
publications examined; and they do not provide a comprehensive summary of
future research topics in the field of IoT privacy that require more attention.

Lin et al. \cite{LinSurvey} undertake a literature review to identify security
and privacy vulnerabilities in the three IoT architecture layers: network,
perception, and application. The authors describe the first six fundamental
security properties for these tiers as confidentiality, integrity, availability,
identification and authentication, privacy, and trust. Then, the authors
look at a variety of security threats for each of the three stages. The authors
wrap up by giving a succinct summary of many privacy-preserving data techniques,
including the stages of data collection, data aggregation, and data analysis.
The authors do, however, largely focus on the IoT's security components and,
as was already said, consider privacy to be one of the most crucial security
aspects, rather than viewing privacy as a distinct concern. Furthermore,
the research does not conduct a thorough gap analysis to discover the
weaknesses of prior efforts.

Based on Ziegeldorf's \cite{ziegeldorf2014privacy} analysis of the literature,
the following are the most prominent privacy concerns in IoT:

\begin{enumerate}
    \item
    The most prominent concern is \textit{identification}, which binds an
    identifier, such as a name and location, with an individual's identity,
    this also enables and aggravates other threats;
    \item
    \textit{Localization and tracking} is the threat of detecting an individual's
    locations through numerous techniques, such as GPS, internet traffic,
    or smartphone location. This threat requires \textit{identification}
    of some kind;
    \item
    In e-commerce, \textit{profiling} is often used for personalization.
    Organizations collect information about individuals in order to deduce
    their interests via association with other profiles and data sources.
    \item
    \textit{Interaction and presentation} allude to the sharing of private
    information with an unintended audience while doing so through a public
    medium. IoT applications often need extensive user interaction, it is
    expected that users of these systems will obtain information via smart
    devices in their immediate surroundings and that users will interface
    with systems in creative, natural ways. However, many of those modes
    of communication and presentation are already available to the broader
    public, making them apparent to anybody around. When personal information
    is transferred between a system and its user, privacy is breached.
    \item
    \textit{Lifecycle transitions} occur when an IoT device is sold, utilized
    by its owner and eventually disposed of. There may be an expectation
    that the object deletes all information, yet smart devices frequently
    keep massive volumes of data about their own past throughout their entire
    existence. This might contain personal images and videos, which are not
    always erased following ownership transfer.
    \item
    \textit{Inventory attacks} involve unauthorized entry and the acquisition
    of information about the presence and characteristics of personal things.
    Malicious users might use inventory data to profile the property and
    break in.
    \item
    \textit{Linkage} is the process of connecting disparate systems, when
    systems are connecting different data sources, there is a higher danger
    of unauthorized access and data leakage.
\end{enumerate}

\subsection{Proposed solutions}

\subsubsection{Creating new ways for user awareness}

There has been some work done to determine the users awareness of their actions
online regarding their privacy. Skirpan et al. \cite{SkirpanPrivacy} built
an interactive theatre experience, this was created to try to prove that
a simulated experience with a credible privacy problem may encourage people
to take action before actually encountering a catastrophe. The plot of the
play consist in a fledgling tech company that unveiled its revolutionary
AI technology while dealing with a company whistleblower and an untimely
zero-day hack on their system. The public is able to interact with the actors
and influence how the story plays out. Audiences and actors were given the
chance to try on roles, behaviors, and opinions that they would not normally
have access to in ordinary life. The authors had interviews and surveys done
after the plays with audience members however they only did interviews halfway
through production and only a small fraction of the audience actually participated
in this data collection, they also noted that after contacting people months
after the interviews that they did not really changed their behaviour regarding
their privacy rights.

\subsubsection{Legislation}

Some papers seek to improve legislation \cite{WEBER2015618, FabianoInternet}
because otherwise, in their view, privacy rights won't be respected if they
are not enforceable legally, they defend that without the express agreement
of the individual concerned, private information obtained by IoT devices
must not be retained or processed in any form, and necessary procedures must
be taken to guarantee that the data collected is not that of an unrelated
individual. But better protection laws for the user would also create opposition
from most companies that want to extract as much private data from their
users without (m)any restrictions in order to increase their profit margins.

\subsubsection{Privacy through security}

Sun et al. \cite{SunSecure} design a lightweight communication strategy for
a remote-control system, employing two types of Virtual-Spaces to achieve
the aim of identity announcement and data exchange. They constructed a prototype
system of the scheme and tested it on the Freenet, demonstrating that the
method can effectively resist the influence of flow analysis on communication
anonymity while preserving communication data security.

\subsubsection{Architecture / Framework Proposals}

Antunes et al. \cite{AntunesFederated} do a SLR on federated learning in
the area of healthcare and make an architecture proposal. The technique known
as federated learning allows for the distributed training of machine learning
models using remotely hosted datasets without the requirement for data amplification.
The fundamental goal of the proposed architecture is to allow healthcare
institutions that have access to sensitive medical information to use it
in distributed data analysis and machine learning research while ensuring
patient confidentiality. Because information transmitted among institutions
need confidentiality guarantees for learning model parameters and analysis
results, the architecture can adopt a number of ways based on a zero-trust
security paradigm \cite{ChenSecurity}. Furthermore, the institutions develop
a learning algorithm verification system that can store and disseminate manifestos,
as well as engage in distributed analytic procedures that need unanimous
agreement from all participants. This study also demonstrates that previous
literature implies that homomorphic encryption and differential privacy are
effective approaches for preventing data breaches without incurring prohibitively
high computing costs.

Opara et al. \cite{opara2022framework} present a system for spotting possible
problems with privacy or security regulations in the early stages of development,
this approach is intended at developers. The paper proposes a domain-specific
ontology for modeling IoT security and privacy policies, a notation for
representing and validating IoT security and privacy policies, a set of
guidelines and rules for detecting IoT policy errors, and a tool for visually
modeling and capturing IoT security policies and discovering policy problems.
Although the framework that is presented is theoretically promising it has
not been tested in a real environment so the effectiveness can't yet be measured.
The authors also don't compare their proposal with others already available.

\subsubsection{Blockchain}

Blockchain is an option to guarantee privacy in IoT because of zero-knowledge
proofs, ring signatures and mixing.

A zero-knowledge proof is a cryptographic technique that enables one party
(the prover) to demonstrate to another (the verifier) that a certain claim
is true without disclosing any information other than the validity of that
claim. Completeness, soundness, and zero-knowledge are the three requirements
that must be satisfied by a zero-knowledge proof method. Completeness means
that the verifier must be able to confirm that the prover is stating the truth
if the information supplied by the prover is true. Soundness indicates that
the verifier must be given the opportunity to contradict the prover's claims
of speaking the truth if the information provided by the prover is untrue.
Zero-knowledge refers to the need that the method only reveal to the verifier
whether the prover is speaking the truth or not.

Ring signatures create a single, recognizable signature that is used to sign
a transaction by combining a number of partial digital signatures from diverse
users. This group, known as the ring, can be chosen at random from the outputs
that other users have made to the blockchain. A ring signature has the security
property that it should be computationally expensive to determine which
of the group's members' keys was used to produce the signature, this is because
it obfuscates the input side of a transaction. A user's anonymity cannot
be taken away from their signature, and any group of users can act as a signing
group automatically.

Mixing is the process of blending possibly traceable digital assets
with others to obscure the original assets' sources. This is frequently done
by pooling source assets from different inputs for a long period and at random
intervals, then spitting them back out to destination addresses. Since they
are all packed together and then delivered at random intervals, it is very
difficult to pinpoint particular assets. Due to the fact that cryptocurrencies
provide a public record of every transaction, mixers have been developed
to improve cryptocurrency privacy. Because of their emphasis on secrecy,
mixers have been used to launder money using cryptocurrency.

Yu et al. \cite{yu2018blockchain} shows various implementations of blockchain
that provide privacy through security, based on different categories like
data integrity, data sharing and authentication and access control. The authors
use privacy as a proxy for security, they also don't discuss the weak and
strong points of each implementation or make any comparison, they also don't
provide further research questions.

Ali et al. \cite{AliIoT} suggest a software stack that combines peer-to-peer
file sharing with blockchain smart contracts to offer IoT users control over
their data and do away with the necessity for centralized IoT data management.
Blockchain smart contracts are used in the proposed `modular consortium'
architecture to regulate access while establishing responsibility for both
data owners and other parties that users grant access to.

\subsubsection{Other proposals}

Zhu et al. \cite{ZhuIntegrating} present an hybrid sensor system that safeguards
privacy while also monitoring parking availability. The authors merged IoT
sensing with crowdsensing and enhanced it with privacy-preserving methods.
The authors employed physical hazy filters to mask IoT sensors in IoT sensing,
and a cryptographic technique based on cryptographic commitments, zero-knowledge
proofs, and anonymous credentials in crowdsensing. In addition, they used
crowdsourcing to create a machine learning model for parking recognition
in the presence of foggy filters. Their paper included proof-of-concept prototypes
such as a Raspberry Pi system and a mobile app, as well as an evaluation
study of the machine learning model and the effects of crowdsourcing.

\subsubsection{Privacy Assistants}

There exists a number of privacy assistants in the market. Privacy assistants
have the objective of giving the user flexibility in choosing the preferred
privacy options in available applications, most are used in smartphones,
very few are made for devices in the IoT.

The Carnegie Mellon University CyLab, which is the university's security
and privacy research institute, started developing in 2019 an IoT Infrastructure
that intended to be free of privacy leaks and software covered by their
Secure and Private IoT Initiative 2019, this project would fall under
their main research theme of Trust. In this project they started the design
of a Personalized Privacy Assistant (PPA) \cite{ColnagoInforming}, this
would involve the use of semi-structured interviews with 17 participants
to examine user perceptions of three hypothetical PPA implementations,
each of which is potentially more autonomous, while outlining the advantages
and disadvantages of each implementation. The interviews were divided into
three sections: exploratory, anchoring and the PPA; While the exploratory
phase's purpose was to learn about participants' attitudes and understanding
of IoT, the anchoring phase aimed to normalize participants' basic understanding
of how IoT functions. In order to get people to think about potential privacy
concerns towards the end of the anchoring section, the authors asked participants
about their opinions on data privacy. In the PPA section, it was proposed
the idea of a PPA for IoT as a potential future project. The authors clarified
that the PPA could distinguish between active data requests such as a gadget
asking biometric information from the user's health tracker and passive data
collection such as a smart device with a microphone that could record people's
utterances while they were nearby. The Notification, Recommendation, and
Auto implementations of an IoT PPA were the three that the authors and attendees
discussed. Notification PPAs can determine which adjacent devices are requesting
data and alert users to those devices' presence and requests so that users
can approve or reject each request. Building on notification PPAs, recommendation
PPAs offer consumers advice on how to share their data based on their preferences.
The user's data sharing decisions would be made by auto PPAs. This would
lessen the cognitive load on consumers but also take away their ability to
influence the process. They found that the participants' attitudes regarding
the various implementations were generally favorable, although they also
voiced worries, which varied depending on the degree of automation. Given
the divergent motivations of participants some desired increased control,
while others wished to avoid being overtaken by notifications and the lack
of agreement regarding the optimal PPA implementation.

After the design phase, the institute implemented a privacy assistant (PA) \cite{FengDesign},
the authors called it IoT Assistant. Because the predominant approach of
"Notice and choice" for data privacy protection, they decided the PA would
also fall into this approach, but because many systems implement notice as
a form of consent, without sometimes offering choices to the end user, they
also wanted this work to provide a conceptual framework that views user-centered
privacy choice as well as a taxonomy for practitioners to use when designing
meaningful privacy choices for their systems. The authors define meaningful
privacy choices as ``the capabilities provided by digital systems for users
to control different data practices over their personal data'', They extend
the notion of privacy choices with five facets: effectiveness (the opportunity
to establish privacy preferences that precisely and completely match the
data collection and use methods that a user is okay with), efficiency (the
capacity to specify these options with the least amount of effort and time),
user awareness (where significant privacy options should be prominently and
clearly communicated to users), comprehensiveness (users should understand
their options, how they affect the gathering and potential use of their data,
as well as what conclusions might be drawn from this data and the potential
repercussions of these conclusions) and neutrality (meaningful privacy decisions
should not be subject to manipulation or bias). The IoT Assistant offers
four privacy settings, giving end users a variety of alternatives to better
suit their varied privacy preferences and as a result, privacy options are
more effective in the IoT environment. The IoT Assistant acts as a centralized
privacy choice platform by implementing various privacy options, allowing
consumers to more effectively govern their data privacy in IoT. The three
IoT system discovery modes that the IoT Assistant supports are QR codes,
push notifications, and location-based map interfaces. These discovery tools
are probably going to make users more aware of the installed IoT devices
and the privacy options they have. Additionally, the united viewpoint of
the integrated notification and option in the the IoT Assistant gives succinct
yet thorough information regarding IoT data practices to help users better
understand the implications of their privacy choices. Additionally, the authors
work to implement the integrated notice and option in the IoT Assistant without
bias or framing, attempting to offer consumers a neutral space to execute
their privacy choices. Although the authors consider the IoT Assistant to
be a significant step towards ``meaningful privacy options'' in IoT, this
assistant still has many issues such as this application is still in the
early stages of it's existence, and because this was created in 2020 and
we are in 2022 there was not much growth. Maybe the main reason this application
was not able to be developed further is that the application itself serves
to show the user the data that is already in the IoT infrastructure that was
created before, and as such it is not capable of identifying new IoT devices
without the end users themselves create on the infrastructure's main webpage \cite{DasPersonalized}
a new entry for the device in question that the user wants to interact with.
Another reason that cripples this application and many like it that want to
provide better privacy in IoT systems is that many systems don't offer any
type of privacy choices to the end user or to other users that are not the
intended end users but the devices are still collecting data about.

The IoT infrastructure that was developed \cite{DasPersonalized} is built
on an open, distributed design that allows for the deployment and management
of IoT resources to be carried out by any number of actors. Part of this
infrastructure is the Internet of Things Resource Registry, it is a web platform
that enables resource owners to declare not only the place where a resource
is deployed but also data practices like the reason(s) for a particular data
collecting process, the level of detail in the data being gathered, retention,
the recipients of the data, and more. Additionally, it discloses any user-configurable
privacy settings that might be connected to a particular resource.

\subsubsection{Sniffers}

IoT sniffers are usually used to detect problems in the networks, they rarely
are used to provide privacy for the users.

The LTEye project \cite{KumarLTE} is an open platform that provides granular
temporal and spatial analytics on the performance of LTE radios without access
to private user data or provider assistance. Despite the presence of multipath,
LTEye uses a revolutionary extension of synthetic aperture radar to communication
signals in order to precisely pinpoint mobile users.

\subsection{Discussion}

There are two main ways to provide privacy in IoT systems, through security
or using privacy notices, other ways like through legislation or with the
creation/usage of a framework that provides privacy fall into these two
categories. Most of the literature assumes that security and privacy are
synonyms, for example \cite{opara2022framework, FabianoInternet, SunSecure},
and so most of the proposed solutions fall under privacy through security.
The proposed solutions that use privacy notices, like \cite{FengDesign}, are
implemented in a way that use other devices like smartphones that provide
the notices themselves, it is hard to provide privacy notices on the IoT devices
themselves because many of these devices don't have a screen or the screen
is too small to provide the necessary information to the user. Because there
are still no standards for implementing privacy notices, and best practices
are scattered throughout the literature, they are mostly implemented haphazardly,
little guidance is given to designers and developers on how to make a privacy
notice design that is sufficient and acceptable for their particular system
and its features. Designers may be unaware of the numerous possibilities for
creating acceptable privacy notifications and, as a result, do not systematically
explore them.

Aleisa and Renaud \cite{aleisa2016privacy} also identify security and privacy
awareness as potential solutions to privacy issues in IoT, but also identify
data minimization, hitchhiking and introspection. Data minimization entails
limiting the collecting of personal information to what is absolutely central
and retaining the data just for as long as is required to satisfy the goal
of the technology's services \cite{ojDirective281}. Hitchhiking \cite{tang2006putting}
is a method of protecting the privacy of users who divulge their location,
applications regard locations as the object of their attention. The fidelity
tradeoff is removed as it is not important to know who is in a certain
location. The introspection \cite{kang2015protection} method examines VM
actions to adequately safeguard users' private information. Every VM's
CPU status, memory contents, network information provided by the hypervisor,
and any malicious software that may be present on the VM are all collected
and analyzed. The privacy of consumers is jeopardized if an IoT device
loses integrity due to a hostile assault.

\section{Privacy Challenges}

IoT is a composed of a complex web of architectures, applications and technologies.
In terms of architectures, it can be decomposed in three layers: the perception
layer, the network layer and the application layer.

The perception layer, also known as the sensor layer, interacts with physical
objects and components via smart devices (RFID, sensors, actuators, and so
on). Its key objectives are to connect objects to the IoT network and to monitor,
collect, and analyze status information about these things using deployed
smart devices. This layer can often be unreliable, for instance with autonomous
vehicles where they find it hard to read road signs or to predict if certain
objects are inanimate or not, but this unreliability also brings privacy
even though the some of the data might be unusable. Noise can also be added
in this layer to provide extra privacy.

In the network layer there are many competing networks like ZigBee, Z-Wave,
Bluetooth Low Energy, LoRa, Wi-fi, etc., this layer is fragmented, specially
in regards to wireless networks, and that makes it very difficult to create
an IoT architecture that can use various networks and have the various
devices communicate with each other, even though interoperability is seen
as a very important factor in IoT. Some of these networks are open standard
protocols while others are proprietary and use different protocols of communication,
use different frequencies, different ranges and different data rates. When
creating an IoT architecture the designers often think of how to solve
specific problems and use what is best for the current needs, and the way
that IoT is fragmented doesn't help in providing progress.

The application layer receives data from the network layer and uses it to
execute essential services or operations. This layer, for example, can provide
the storage service to backup incoming data into a database or the analysis
service to analyze received data in order to predict the future state of
physical devices. This layer encompasses a wide range of applications, each
with its own set of requirements. A few examples are smart grids, smart transportation,
and smart cities.

According to Qu et al. \cite{Qu2018Privacy}, several significant barriers
remain, including the lack of a theoretical foundation, the trade-off optimization
between privacy and data value, and system isomerism over-complexity. Because
there are no mathematical foundations for IoT structure design, IoT system
designs are planned and executed using empirical approaches, which have limitations
in IoT development. Scientific theory and quantitative analysis must enable
trade-off optimization, yet, there are multiple parties with diverse characteristics
and requirements, making this optimization highly challenging. A plethora
of standards and protocols add to the unneeded complexity of system isomerism.
Ensuring effective IoT applications while wasting as little resources as feasible
implies less resources available for privacy protection, however, lightweight
privacy protection cannot fulfill all of the criteria, and attackers can
exploit structural information to launch several concurrent attacks.

\section{Methodology}

This paper conducted a systematic literature review of the most relevant papers
discussing methodologies and techniques for the protection of users' privacy
data with special focus on IoT systems. For this SLR, this paper considered
focusing only on papers from the last 12 years, from 2010 until 2022, since
papers before then become out of date with the evolution of technology. In
this SLR, it was reviewed 100 (*\textbf{\color{red}number to be adjusted})
papers published in top computer science, security, privacy and software
engineering outlets.

This paper followed Keshav's three-pass approach \cite{KeshavHow} when choosing
which papers to read fully and which ones to ignore, first the title would
be read, then the abstract, the introduction and conclusion and briefly skim
the rest of the paper and then decide if it was worth reading any further,
the focal point in this phase was answering the following question: does
the paper present a new methodology or interesting angle to tackle users'
privacy concerns? Only then the document would be read in it's entirety while
ignoring any tables, figures, images or graphs. If the paper failed to present
any interesting idea, approach, or technique it would be discarded, but if
not, it would be read carefully from the beginning again in order to fully
understand what it presents.

Having collected the major findings, this work then aims to conduct a throughout
study split in several stages and around the following research questions:

\textbf{RQ1:} What approaches are being considered for privacy issues in
IoT in the currently available literature?

\textbf{RQ2:} What IoT-related tools are available that empower users to
protect their privacy rights? OR How to empower users to protect their privacy
rights?

\textbf{RQ3:} What issues are prevalent in IoT that make it difficult to
address privacy and security problems?

The proposed methodology is composed of two phases, the first phase consists
on doing a study on people's general privacy concerns while using and interacting
with IoT devices. This study will consist on preparing a questionnaire to
assess general user's knowledge on privacy concepts, their habits and concerns,
their understanding of privacy rights, and what they do to safeguard those
rights. The goal of this study is to both understand the privacy paradox
and collect data on their proposal to address privacy issues with regard
to IoT devices.

\textbf{\color{red}TODO: ADD PHASE TWO}


\subsection{Study}

This study was done to try to understand people's perception of IoT and their
privacy practices online. It also serves to demystify the privacy paradox
and also to help provide a solution to the privacy issue in IoT. The questionnaire
consists of 92 questions divided into 7 sections to access users' knowledge,
it follows a kind of narrative, the first section being about general privacy
questions, the second section about the predisposition to data sharing, the
third about preoccupations with privacy, the fourth about daily digital routines,
the fifth about profile identification, the sixth about IoT general knowledge
and finally a section about non-identifiable demographic data. The scale
that is used in the questionnaire to assess online privacy concerns both
on a vertical and horizontal level is based on the book by Philip K. Masur \cite{masur2018situational}.
Great care is taken when it comes to this survey's data collection, in order
to not identify any individual or group of individuals, for instance, when
it comes to differential privacy, any data that might identify someone will
not be disclosed, even though the results might suffer from some inaccuracy
because of this.

This survey was partially based in a study done in the Philippines by the
government in the context of their privacy act of 2012 \cite{Philippine2022Conduct},
this was the second survey done on the country's population. It was also
inspired by Alves's master's thesis \cite{alves2021}, which was about portuguese
citizen's perception about privacy in the wake of GDPR.

This survey was done through the internet, it was created in Google Forms,
this way it is guaranteed to reach the most people possible in the country
and abroad.

\textbf{TODO: Extend this subsection}

\subsection{Application}

The main objective of this application is the following:

\section{Discussion}

The study found the following... The app...

\section{Future work}

Although there exist some hardware devices that can detect some devices
on some networks, like ZigBee or Bluetooth LE, namely IoT sniffers and
there exist some georeferencing applications that try to pinpoint certain
IoT devices, there is still a need for some kind of device or framework
that is network agnostic and can detect where the devices are located and
what kind of data the IoT devices that are around it are collecting.
This gadget should also be capable of informing the users about the privacy
notices of the devices and what can the users do to safeguard their data.
The IoT sniffers that are available are primarily used in the detection of
problems in the communication of devices in the network or to solve problems
of interoperability between different IoT networks. There are many obstacles
that impede the creation of such a gadget and the fact that it still doesn't
exist anything like it shows that maybe there is not enough interest from
users or researchers to focus on such an endeavour or the complexity
of such a task is greater than the rewards.

\section{Conclusion}

In this thesis I explored people's perception of privacy of IoT systems and
made an application that aims to create more awareness in users about their
environment and the IoT devices that inhabit it.

\section*{Acknowledgment}

% I would like to acknowledge the following people: Person 1, Person 2, Person 3.
The preferred spelling of the word ``acknowledgment'' in America is without
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B.
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor
acknowledgments in the unnumbered footnote on the first page.

\bibliographystyle{IEEEtran}
\bibliography{assets/references}

\section*{Appendix}

\end{document}
