\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\graphicspath{ {./assets/} }
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Empowering Users' Privacy Rights in the Internet of Things\\
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Nelson Vieira}
\IEEEauthorblockA{\textit{Faculdade de CiÃªncias Exatas e da Engenharia} \\
\textit{Universidade da Madeira}\\
Funchal, Portugal \\
2080511@student.uma.pt}
}

\maketitle

\begin{abstract}
Internet of things (IoT) devices are everywhere, since the birth of ubiquitous
computing that human every day life is envisioned containing millions of devices
that control every aspect of our lives. Today we have smart cars, smart houses,
smart cities, wearables among other things that use various types of devices
and various types of networks to communicate. These devices create new ways
of collecting and process personal data from users and non-users.
Most end users aren't even aware or have little control over the information that
is being collected by these systems. I tried to take a holistic approach to this
problem by first doing a systematic literature review (SLR), then by doing a survey to gather
information about the general knowledge of Portugal's population in this
very topic and then, partly based in the information I gathered, I propose
a system that gives users information about the devices that are nearby
and how to protect the data that they don't want to share with these devices,
this system is capable of detecting what type of devices are nearby,
what kind of data is collected by these devices, show privacy choices
to the user when it is possible to do so and what can be done to protect
unwanted data from being collected.
\end{abstract}

\begin{IEEEkeywords}
privacy, Internet of Things, ubiquitous computing, privacy assistant
\end{IEEEkeywords}

\section{Introduction}
Privacy as we know it is a somewhat recent concept \cite{vincent2016privacy, moore2017privacy},
before the digital age there was barely any notion of privacy for most people. For many centuries
most people used to reside in small communities where they were continuously involved in one
another's lives. Even more recent is the idea that privacy is a crucial component of
personal security, in contrast to the undeniable necessity of public security, including
the requirement for guarded walls and closed doors. Long considered a luxury, privacy is
still frequently viewed as nice-to-have rather than an absolute necessity, even if it is
recognized as an human right, as present in article 12 of the Universal Declaration of Human Rights
\cite{RooseveltUniversal}: ``No one shall be subjected to arbitrary interference with his privacy, family,
home or correspondence, nor to attacks upon his honour and reputation. Everyone has
the right to the protection of the law against such interference or attacks.''. Privacy can
be defined \cite{InternationalWhat, SpiekermannEngineering} as the right to govern
how personal information and data is collected, stored, and used, it frequently
involves handling sensitive information with care, and as such, organizations must
be open and honest about the kind of data they plan to gather, why they need it, and
where and with whom they plan to share it. Users should have the right to control their
shared information.

This definition can cause some confusion with the idea of
security \cite{HIVDifference} and although privacy and security are interconnected, security
involves measures taken to safeguard data from risk, threat or danger,
it frequently alludes to safety. It is the practice of keeping users'
personal information and data safe and preventing unauthorized access to it.
The main distinction between privacy and security is that the former deals with
information that is specific to users and how they wish their data is to
be used and managed, whilst the latter deals with its protection from
potential dangers. Security can exist without privacy,
but the opposite is not true. For managing sensitive and personal data, privacy and
computer security are equally crucial.

Concerns about digital privacy have been growing \cite{emami2019exploring, park2022personal, zhang2022peer} in the last few
years, especially after the \textit{Anonymous} decentralized hacker group
cyber attacks, \textit{WikiLeaks} and Snowden's leaked top secret documents from United State's
National Security Agency,
these concerns can be noted with the increase of written literature on the subject,
when searching for terms like ``privacy'', ``online privacy'',
``digital privacy'' in Google Scholar, ACM Digital Library or Science Direct it
can be seen that, in the last 5 years, it returns about 5000000, 650000 and 80000
documents respectively, including articles, books, conference papers etc.

Most research has been done with focus on the web, while privacy in IoT
systems has not been explored as much, although IoT systems have been
growing each year, this creates new ways to interact,
collect and analyze data.
Because it already exists a healthy amount of research out there
focusing on web privacy and not on IoT privacy, it is a much more
fertile ground to explore the theme of privacy in the context of
Internet of Things devices.

Iot as a term began being used in the 90's, a connection can be drawn
with Mark Weiser's article on ubiquitous computing \cite{weiser1991computer} and the rise
of devices of various sizes that communicate with each other to do
various (small) tasks, that make Weiser's idea a reality. These devices are
used in various applications, beginning at home \cite{marikyan2019systematic} with thermostats,
fridges, microwaves, etc, in smart cars \cite{arena2020overview}, in the education system \cite{al2020survey},
in our clothes and our watches \cite{niknejad2020comprehensive} and even into outer space \cite{AkyildizInternet}.
IoT resources may include IoT equipment (like smart home assistants and
autonomous vehicles), IoT services (like video analytics services linked to
smart cameras and indoor position tracking systems), or IoT apps
(like smart TV remote apps) that track and use information about us.
The first use of the term \textit{Internet of Things} was in 1999 by Kevin Ashton \cite{KevinThat},
executive director of the Auto-ID Center of MIT, during a presentation for Procter \& Gamble.

The Internet of Things can be defined as: ``An open and
comprehensive network of intelligent objects that have the capacity to auto-organize,
share information, data and resources, reacting and acting in face of situations
and changes in the environment'' \cite{madakam2015internet}.

IoT is one of the fastest growing technologies \cite{MohammadState},
it is predicted that it will grow into the trillions of devices by 2030 \cite{SarawiInternet},
and with this expansion new security vulnerabilities and data gathering dangers appear, the lack
of security in these devices makes them ideal targets for privacy violations and inadequate
customer disclosure of device capabilities and data practices aggravates
privacy and security issues.

Privacy in IoT systems in not seen as a crucial factor in development \cite{alhirabi2021security}.
Specific standards for privacy options have been imposed by
data privacy regulations including the General Data Protection Regulation (GDPR)
and California Consumer Privacy Act (CCPA), but even these regulations have
been criticized \cite{peloquin2020disruptive, gladis2022weaponizing, gentile2022deficient, green2022flaws, byun2019privacy}.

\section{Literature review}

In this section I conduct a systematic literature review of the most relevant papers
discussing methodologies and techniques for the protection of users' privacy data
with special focus on IoT systems. For this SLR I considered focusing only
on papers from the last 12 years, from 2010 until 2022, since papers before then
become out of date with the evolution of technology. I reviewed 100 (*\textbf{\color{red}number to be adjusted}) papers published
in top computer science, security, privacy and software engineering outlets.

I followed Keshav's three-pass approach \cite{KeshavHow} when choosing which
papers to read fully and which ones to ignore, first I would read the title, abstract,
introduction and conclusion and briefly skim the rest of the paper and then
decide if it was worth reading any further, the focal point in this phase was
answering the following question: does the paper present a new methodology or
interesting angle to tackle users' privacy concerns? Only then the document would
be read in it's entirety while ignoring any tables, figures, images or graphs.
If the paper failed to present any interesting idea, approach, or
technique it would be discarded, but if not, it would be read carefully from
the beginning again in order to fully understand what it presents.

\subsection{What is the privacy paradox?}

The use of a variety of digital devices have numerous advantages, but
they also bring with them the ubiquity of data capturing equipment, therefore,
it is understandable why the majority of online users have serious concerns
about the privacy of their personal data. However, the opinions expressed
are starkly at odds with the reality that just one in four European users
read the terms and conditions in their entirety prior to making an online
purchase or subscribing to a service, 59\% admitted to only quickly scanning
the terms and conditions before completing a purchase, while 14\% admitted
to never reading them at all, 30\% of the respondents would even swap
their email address to win a reward, or entry into a raffle, while 17\% would
do so to get an app and 30\% would do it for money \cite{DarrenState}.

This is what is called a privacy paradox, there have been multiple papers
written on this subject \cite{solove2021myth, WilliamsPrivacy, lee2021investigating, goad2021privacy, gerber2018explaining},
some papers attempt a theoretical explanation while others attempt an empirical one.
There has been very different interpretations or explanations of this paradox,
a few papers \cite{wilson2012unpacking, warshaw2015can, lee2015privacy} apply the theoretical concept of the \textit{homo economicus} \cite{zak2008moral},
which is the representation of people as beings who constantly act in a way
that is logical and self-interested, not worrying about morality or ethics, and
who do so to the best of their ability, to the context of privacy.
Different cognitive biases and heuristics can influence how consumers make decisions,
according to several studies on consumer choice behavior \cite{acquisti2007can, knijnenburg2013dimensionality, wakefield2013influence, flender2012type}.
According to several articles \cite{dienlin2015privacy, baek2014solving}, this paradox might be explained by the
fact that some people have genuinely experienced online privacy assaults
and that most privacy views are therefore based on heuristics or secondhand accounts.
Taddicken's study \cite{taddicken2014privacy} argues that peer pressure is the reason people have this contradictory behavior,
Norberg et al. \cite{norberg2007privacy} explain this paradox by suggesting that while perceived
risk affects reported attitudes and behavioral intentions, trust has a direct
impact on privacy behavior, while others \cite{flender2012type, kokolakis2017privacy} rely on quantum theory.
Brandimarte et al. \cite{brandimarte2013misplaced} have explored the idea that when it comes to their
data privacy, users have an \textit{illusion of control}.

This paradox has been proven to be vitiated by a number of empirical studies \cite{dienlin2015privacy, xie2019consumers, SCHWAIG20131, sannon2018privacy},
online privacy practices are founded on separate privacy mindsets and so they are not inherently paradoxical.

\subsection{Literature overview}

According to this systematic literature review \cite{Gupta2022Privacy} most papers
that have written about privacy in iot systems focus in one or two devices,
ignore the sensitivity of collected information, don't emphasize real-time
notification to users and.

another SLR \cite{KUHTREIBER2022101656} analyses what tools are available for developers
to implement iot systems with privacy in mind.

\cite{AbbottPrivacy} explores privacy in the context of smart homes.

\subsection{Proposed solutions}

\subsubsection{Creating ways for user awareness}

For the literature review interactive theatre experience \cite{SkirpanPrivacy}

\subsubsection{Legislation}

Some papers propose better laws \cite{} as a way to force service providers
to give more choices to users, but as stated in the paper this
approach will be met with opposition from most companies because
most of them have a stake in keeping things the way they are.

\subsubsection{Privacy through security}

\cite{SunSecure} proposes a crowd system to achieve total anonymity.
\cite{ZhaoSurvey} proposes Differential Privacy for Unstructured Data Content.

\subsubsection{Architecture Proposal}

\cite{AntunesFederated} makes an Architecture Proposal.

\subsubsection{Other?}

\cite{ZhuIntegrating} explores an integrated paradigm called ``hybrid sensing'' where users interact with a crowdsensing server via a privacy-preserving protocol to preserve their anonymity.

\subsubsection{Privacy Assistants}

There exists a number of privacy assistants in the market. Privacy assistants
have the objective of giving the user flexibility in choosing the
preferred privacy options in available applications, most are used in
smartphones, very few are made for devices in the internet of things.

The Carnegie Mellon University CyLab, which is the university's security and
privacy research institute, started developing in 2019 an IoT Infrastructure
that intended to be free of privacy leaks and software covered by their
Secure and Private IoT Initiative 2019, this project would fall under their
main research theme of Trust. In this project they started the design of a
Personalized Privacy Assistant (PPA) \cite{ColnagoInforming}, this would involve the use of semi-structured
interviews with 17 participants to examine user perceptions of three hypothetical
PPA implementations, each of which is potentially more autonomous,
while outlining the advantages and disadvantages of each implementation.
The interviews were divided into three sections: exploratory, anchoring and the PPA;
While the exploratory phase's purpose was to learn about participants' attitudes
and understanding of IoT, the anchoring phase aimed to normalize participants' basic
understanding of how IoT functions. In order to get people to think about potential
privacy concerns towards the end of the anchoring section, the authors asked
participants about their opinions on data privacy. In the PPA section, it was proposed
the idea of a PPA for IoT as a potential future project. The authors clarified that
the PPA could distinguish between active data requests such as a gadget asking
biometric information from the user's health tracker and passive data collection
such as a smart device with a microphone that could record people's utterances
while they were nearby. The Notification, Recommendation, and Auto implementations
of an IoT PPA were the three that the authors and attendees discussed.
Notification PPAs can determine which adjacent devices are requesting data
and alert users to those devices' presence and requests so that users can
approve or reject each request.
Building on notification PPAs, recommendation PPAs offer consumers advice
on how to share their data based on their preferences.
The user's data sharing decisions would be made by auto PPAs. This would
lessen the cognitive load on consumers but also take away their ability to
influence the process.
They found that The participants' attitudes regarding the various implementations
were generally favorable, although they also voiced worries, which varied
depending on the degree of automation. Given the divergent motivations of
participants some desired increased control, while others wished to avoid
being overtaken by notifications and the lack of agreement regarding the
optimal PPA implementation.

After the design phase, the institute implemented a privacy assistant (PA) \cite{FengDesign},
the authors called it IoT Assistant, because the predominant approach of
"Notice and choice" for data privacy protection, they decided the PA would
also fall into this approach, but because many systems implement notice as
a form of consent, without sometimes offering choices to the end user, they
also wanted this work to provide a conceptual framework that views user-centered
privacy choice as well as a taxonomy for practitioners to use when designing meaningful
privacy choices for their systems. The authors define
meaningful privacy choices as "the capabilities provided by digital
systems for users to control different data practices over their personal data", They
extend the notion of privacy choices with five facets: effectiveness (the opportunity to
establish privacy preferences that precisely and completely match the data
collection and use methods that a user is okay with), efficiency
(the capacity to specify these options with the least amount of effort and time),
user awareness (where significant privacy options should be prominently and clearly
communicated to users), comprehensiveness (users should understand their options,
how they affect the gathering and potential use of their data, as well as what
conclusions might be drawn from this data and the potential repercussions of
these conclusions) and neutrality (meaningful privacy decisions should not be
subject to manipulation or bias). The IoT Assistant offers four privacy settings, giving end users
a variety of alternatives to better suit their varied privacy preferences and as a result,
privacy options are more effective in the IoT environment. The IoT Assistant acts as a
centralized privacy choice platform by implementing various privacy options, allowing
consumers to more effectively govern their data privacy in IoT. The three IoT system
discovery modes that the IoT Assistant supports are QR codes, push notifications,
and location-based map interfaces. These discovery tools are probably going to make
users more aware of the installed IoT devices and the privacy options they have.
Additionally, the united viewpoint of the integrated notification and option in the
the IoT Assistant gives succinct yet thorough information regarding IoT data practices to help users
better understand the implications of their privacy choices. Additionally, the authors
work to implement the integrated notice and option in the IoT Assistant without bias or framing,
attempting to offer consumers a neutral space to execute their privacy choices.
Although the authors consider the IoT Assistant to be a significant step towards
``meaningful privacy options'' in IoT, this assistant still has many issues such as
this application is still in the early stages of it's existence, and because this was
created in 2020 and we are in 2022 there was not much growth. Maybe the main reason
this application was not able to be developed further is that he application itself
serves to show the user the data that is already in the IoT infrastructure that was created before,
and as such it is not capable of identifying new IoT devices without the end users themselves
create on the infrastructure's main webpage \cite{DasPersonalized} a new entry for the device in question that the
user wants to interact with. Another reason that cripples this application and many like
it that want to provide better privacy in IoT systems is that many systems don't
offer any type of privacy choices to the end user or to other users that are not
the intended end users but the devices are still collecting data about.

The IoT infrastructure that was developed \cite{DasPersonalized} is built on an open, distributed design
that allows for the deployment and management of IoT resources to be carried out
by any number of actors. Part of this infrastructure is the Internet of Things Resource Registry,
it is a web platform that enables resource owners to declare not only the place where a
resource is deployed but also data practices like the reason(s) for a particular data collecting
process, the level of detail in the data being gathered, retention, the recipients of the data,
and more. Additionally, it discloses any user-configurable privacy settings that might be
connected to a particular resource.

A similar project is LTEye \cite{KumarLTE} that is an open
platform that provides granular temporal and spatial analytics on the performance of LTE
radios without access to private user data or provider assistance. Despite the presence of
multipath, LTEye uses a revolutionary extension of synthetic aperture radar to communication
signals in order to precisely pinpoint mobile users.
\\*[11pt]
\textbf{TODO: from here forward}


\section{Methodology}

The proposed methodology is composed of two phases, the first phase consists of
making a study on the region's general concern with their privacy when
using and interacting with IoT devices, their knowledge of privacy rights, what they do to
protect their privacy rights. One one side the objective of this study
consist in demystifying the privacy paradox in the region and gather
information about their idea to solve this problem with respect
to iot devices.
The second phase consists in doing an application that can detect iot devices
nearby the user with at least a 10 meters radius. The application should
do the following when detecting a device:
1. it should show some information about the device;
2. it should categorize the device;
3. it should provide the user with privacy options, if the device allows the
user to decline data harvesting.
This application at first sight might appear to be a mere privacy assistant but
it's not, because iot assistants merely choose what privacy options
the user first sets and maintains it for every other application that the user
might use. The proposed app doesn't have the objective to conform to the
user's preferred privacy choices, it merely informs the user about nearby iot
devices and can provide the user with privacy options. But the main objective
is creating awareness in individuals about the various devices that are around
and make the user questions their choices.

\subsection{User Awareness}\label{AA}
There has been some work done to determine the users awareness of
their actions online in regard to privacy. An interactive theatre experience \cite{ColnagoInforming}
was proposed in order to expose privacy malpractices in companies,
specially in the capitalistic world where profit is prioritize
above all else, in this experiment the public is able to interact with
the actors and influence the story of the play, there are various endings depending
on the public's choices throughout the play, some endings the company would
bury the corruption that was going on, in another ending a team of hackers
is able to expose the company's practices to the world. After the play
the team responsible for the experiment would talk with public members about
what they experienced and discussed what was it about and the members
practices with their data on their daily life. After some months
the team would talk again with the members that were present in the play and
talk about any changes they have done in the meantime, most said they did
not change their behavior, one member said that it took more care of The
information that made available online because it had a bad experience before
where some private data was exposed that should have not been exposed. All in
all the experiment did not prove to be a success in changing people's behavior.

\section{Study}

This study was done to try to understand people's perception of IoT and their
privacy practices online. It was partially based in a study done in the Philippines by the
government in the context of their privacy act of 2012, this was the second survey done
on the population.
This survey was done through the internet, it was created in google forms, this way it
is guaranteed to reach most people in the country.

\section{Application}

I created something and ...

\section{Discussion}

The study found the following... The app...

\section{Conclusion}

In this thesis I explored people's perception of privacy of IoT systems and
made an application that aims to create more awareness in users about their
environment with IoT devices around them.

\section*{Acknowledgment}

% I would like to acknowledge the following people: Person 1, Person 2, Person 3.
The preferred spelling of the word ``acknowledgment'' in America is without
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B.
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor
acknowledgments in the unnumbered footnote on the first page.

\bibliographystyle{IEEEtran}
\bibliography{assets/references}

\end{document}
